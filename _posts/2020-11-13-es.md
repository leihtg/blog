---
layout: post
title: es相关知识点
categories: guide
tags: guide es
author: leihtg
---

#### 安装配置

默认不能用root用户启动

##### ES目录介绍

* bin：可执行文件在里面，运行es的命令就在这个里面，包含了一些脚本文件等 
* config：配置文件目录 JDK：java环境 lib：依赖的jar，类库 
* logs：日志文件 
* modules：es相关的模块 
* plugins：可以自己开发的插件 
* data：这个目录没有，自己新建一下，后面要用 -> mkdir data，这个作为索引目录

##### 修改核心配置文件 elasticearch.yml

* 修改集群名称，默认是elasticsearch，虽然目前是单机，但是也会有默认的 

* 为当前的es节点取个名称，名称随意，如果在集群环境中，都要有相应的名字

  ```bash
  cluster.name: my-application
  node.name: node-1
  path.data: /home/lht/elastic/elasticsearch-7.10.0/data
  path.logs: /home/lht/elastic/elasticsearch-7.10.0/logs
  network.host: 0.0.0.0
  cluster.initial_master_nodes: ["node-1"]
  # 其他用默认配置就行了
  ```

##### 修改配置文件jvm.options

如果内存不够要修改，默认是1G

```bash
-Xms128m
-Xmx128m
```

##### 启动

直接执行命令

> ./bin/elasticsearch

![]({{site.baseurl}}/assets/20201113/微信截图_20201114093139.png)

如果出现上图的错误则需要修改一下环境变量

```bash
#对于前两个问题，配置完后需要重启
vim /etc/security/limits.conf
# 在文件末尾添加
* soft nofile 65536
* hard nofile 131072
* soft nproc 4096
* hard nproc 4096
```

```bash
#对于第三个问题
vim /etc/sysctl.conf 
# 文件末尾添加
vm.max_map_count=262145
# 然后执行下面命令刷新一下
sysctl -p
```



#### 核心概念

ES -> 数据库 
		索引index -> 表 
		文档 document -> 行（记录） 
		字段 fields -> 列

#### 元数据

* _index：文档数据所属那个索引，理解为数据库的某张表即可。 
* _type：文档数据属于哪个类型，新版本使用 _doc 。 
* _id：文档数据的唯一标识，类似数据库中某张表的主键。可以自动生成或者手动指定。 
* _score：查询相关度，是否契合用户匹配，分数越高用户的搜索体验越高。 
* _version：版本号。 
* _source：文档数据，json格式。

##### 内置分词器

* standard：默认分词，单词会被拆分，大小会转换为小写。
* simple：按照非字母分词。大写转为小写。
* whitespace：按照空格分词。忽略大小写。
* stop：去除无意义单词，比如 the / a / an / is …
* keyword：不做分词。把整个文本作为一个单独的关键词。

#### 集群相关

分片（shard）：把索引库拆分为多份，分别放在不同的节点上，比如有3个节点，3个节点的所有数据内容加在一起是一个完整的索引库。分别保存到三个节点上 水平扩展，提高吞吐量。
		备份（replica）：每个shard的备份。

shard = primary shard（主分片） replica = replica shard（备份节点）

#### 倒排索引

倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中每一项都包括一个属性值和包含该属性值的各个记录地址。由于不是根据记录来确定属性，而是根据属性来确定记录的位置，所以称之为倒排索引。



![]({{site.baseurl}}/assets/20201113/微信截图_20201113214946.png)

### ES集群

![]({{site.baseurl}}/assets/20201113/微信截图_20201114154046.png)

![]({{site.baseurl}}/assets/20201113/微信截图_20201114154233.png)

#### Elasticsearch集群的概念

**引子**

单机es可以用，没毛病，但是有一点我们需要去注意，就是高可用是需要关注的，一般我们可以把es搭建成集群，2台以上就能成为es集群了。集群不仅可以实现 能实现海量数据存储的横向扩展。

**分片机制**

每个索引可以被分片，就相当于吃披萨的时候被切了好几块，然后分给不同的人吃

* 索引my_doc只有一个主分片； 
* 索引shop有3个主分片； 
* 索引shop2有5个主分片。 
* 每个主分片都包含索引的数据，由于目前是单机，所以副本分片是没有的，这个时候集群健康值显示为黄色。 
* 副本分片是主分片的备份，主挂了，备份还是可以访问，这就需要用到集群了。
* 同一个分片的主与副本是不会放在同一个服务器里的，因为一旦宕机，这个分片就没了

##### **搭建Elasticsearch集群**

**配置集群**

修改 `elasticsearch.yml` 这个配置文件如下：

```bash
# 配置集群名称，保证每个节点的名称相同，如此就能都处于一个集群之内了 
cluster.name: imooc-es-cluster 
# 每一个节点的名称，必须不一样 
node.name: es-node1 
# http端口（使用默认即可） 
http.port: 9200 
# 主节点，作用主要是用于来管理整个集群，负责创建或删除索引，管理其他非master节点（相当于企业老总） 
node.master: true 
# 数据节点，用于对文档数据的增删改查 
node.data: true 
# 集群列表 
discovery.seed_hosts: ["192.168.1.184", "192.168.1.185", "192.168.1.186"] 
# 启动的时候使用一个master节点 
cluster.initial_master_nodes: ["es-node1"] 
```

最后可以通过如下命令查看配置文件的内容：

> more elasticsearch.yml | grep ^[^#] 

#### 集群脑裂

**什么是脑裂**

如果发生网络中断或者服务器宕机，那么集群会有可能被划分为两个部分，各自有自己的master来管理，那么这就是脑裂。

**脑裂解决方案**

master主节点要经过多个master节点共同选举后才能成为新的主节点。就跟班级里选班长一样，并不是你1个人能决定的，需要班里半数以上的人决定。
解决实现原理：半数以上的节点同意选举，节点方可成为新的master。

```bash
discovery.zen.minimun_master_nodes=(N/2)+1
#N为集群的中master节点的数量，也就是那些 node.master=true 设置的那些服务器节点总数。
```

在最新版7.x中， minimum_master_node 这个参数已经被移除了，这一块内容完全由es自身去管理，这样就避免了脑裂的问题，选举也会非常快。



#### 附：操作ES的API

官网地址： https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html

1. 集群健康

   > GET     /_cluster/health 

2. 创建索引

    > PUT     /index_test
    
    ```json
    {
        "settings": {
            "index": {
                "number_of_shards": "2",
                "number_of_replicas": "0"
            }
        }
    }
    ```

3. 查看索引

   > GET     _cat/indices?v 

4. 删除索引

   > DELETE      /index_test 

5. 索引的mappings映射

   1. 索引分词概念

      index：默认true，设置为false的话，那么这个字段就不会被索引

   2. 创建索引的同时创建mappings

      > PUT     /index_str

      ```json
      {
      	"mappings": {
      		"properties": {
      			"realname": {
      				"type": "text",
      				"index": true
      			},
      			"username": {
      				"type": "keyword",
      				"index": false
      			}
      		}
      	}
      }
      ```

   3. 查看分词效果

      > GET         /index_mapping/_analyze 

      ```json
      {
      	"field": "realname",
      	"text": "imooc is good"
      }
      ```

   4. 尝试修改

      > POST        /index_str/_mapping 

      ```json
      {
      	"properties": {
      		"name": {
      			"type": "long"
      		}
      	}
      }
      ```

   5.  为已存在的索引创建或创建mappings

      > POST        /index_str/_mapping 

      ```json
      {
      	"properties": {
      		"id": {
      			"type": "long"
      		},
      		"age": {
      			"type": "integer"
      		}
      	}
      }
      ```

6. 文档的基本操作 

   1. 添加

      > POST /my_doc/_doc/1 -> {索引名}/_doc/{索引ID}（是指索引在es中的id，而不是这条记录的id

      ```json
      {
      	"id": 1001,
      	"name": "imooc-1",
      	"desc": "imooc is very good, 慕课网非常牛！",
      	"create_date": "2019-12-24"
      }
      ```

   2.  删除

      > DELETE /my_doc/_doc/1 

      * 注：文档删除不是立即删除，文档还是保存在磁盘上，索引增长越来越多，才会把那些曾经标识过删除的，进行清理，从磁盘上移出

   3. 修改文档

      * 局部：

        > POST /my_doc/_doc/1/_update 

        ```json
        {
        	"doc": {
        		"name": "慕课"
        	}
        }
        ```

      * 全量替换

        > PUT /my_doc/_doc/1 

        ```json
        {
        	"id": 1001,
        	"name": "imooc-1",
        	"desc": "imooc is very good, 慕课网非常牛！",
        	"create_date": "2019-12-24"
        }
        ```

        注：每次修改后，version会更改

   4.  查询文档

      1. 常规查询

         > GET /index_demo/_doc/1 
         >
         > GET /index_demo/_doc/_search 

         查询结果

         ```json 
         {
         	"_index": "my_doc",
         	"_type": "_doc",
         	"_id": "2",
         	"_score": 1.0,
         	"_version": 9,
         	"_source": {
         		"id": 1002,
         		"name": "imooc-2",
         		"desc": "imooc is fashion",
         		"create_date": "2019-12-25"
         	}
         }
         ```

      2. 定制结果集

         >GET /index_demo/_doc/1?_source=id,name 
         >
         >GET /index_demo/_doc/_search?_source=id,name 

      3. 判断文档是否存在

         > HEAD /index_demo/_doc/1 

7. 文档乐观锁控制 if_seq_no与if_primary_term

   1. 版本元数据

      * _seq_no：文档版本号，作用同_version（相当于学生编号，每个班级的班主任为学生分配编号，效率要比学校教务处分配来的更加高 来更方便） 
      * _primary_term：文档所在位置（相当于班级） 

   2. 插入新数据

      > POST /my_doc/_doc 

      ```json
      {
      	"id": 1010,
      	"name": "imooc-1010",
      	"desc": "imoocimooc！",
      	"create_date": "2019-12-24"
      }
      # 此时 _version 为 1 
      ```

   3. 修改数据

      > POST    /my_doc/_doc/{_id}/_update 

      ```json
      {
      	"doc": {
      		"name": "慕课"
      	}
      } 
      # 此时 _version 为 2 
      ```

   4. 模拟两个客户端操作同一个文档数据，_version都携带为一样的数值

      ```json
      # 操作1 
      POST    /my_doc/_doc/{_id}/_update?if_seq_no={数值}&if_primary_term={数值} 
      {
      	"doc": {
      		"name": "慕课1"
      	}
      }
      # 操作2 
      POST    /my_doc/_doc/{_id}/_update?if_seq_no={数值}&if_primary_term={数值} 
      {
      	"doc": {
      		"name": "慕课2"
      	}
      }
      ```

8. 分词与内置分词器

   什么是分词？

   把文本转换为一个个的单词，分词称之为analysis。es默认只对英文语句做分词，中文不支持，每个中文字都会被拆分为独立的个体。

   > POST /_analyze 

   ```json
   {
   	"analyzer": "standard",
   	"text": "text文本"
   }
   ```

   > POST /my_doc/_analyze 

   ```json
   {
   	"analyzer": "standard",
   	"field": "name",
   	"text": "text文本"
   }
   ```

9. IK中文分词器

   Github：https://github.com/medcl/elasticsearch-analysis-ik

   1. 自定义中文词库

       在{es}/plugins/ik/config下，创建：

      > vim custom.dic 

   2.  并且添加内容

      > 慕课网
      >
      > 骚年

   3. 配置自定义扩展词典

      <entry key="ext_dict">custom.dic</entry>

   4. 重启es

10. DSL搜索

    1. 请求参数的查询(QueryString)

       查询[字段]包含[内容]的文档

       > GET     /shop/_doc/_search?q=desc:慕课网 
       > GET     /shop/_doc/_search?q=nickname:慕&q=age:25 

       text与keyword搜索对比测试(keyword不会被倒排索引，不会被分词)

       > GET     /shop/_doc/_search?q=nickname:super 
       > GET     /shop/_doc/_search?q=username:super 
       > GET     /shop/_doc/_search?q=username:super hero 

       这种方式称之为QueryString查询方式，参数都是放在url中作为请求参数的。

    2. DSL基本语法

       QueryString用的很少，一旦参数复杂就难以构建，所以大多查询都会使用dsl来进行查询更好。

       * Domain Specific Language 
       * 特定领域语言 
       * 基于JSON格式的数据查询 
       * 查询更灵活，有利于复杂查询

       DSL格式语法

       ```
       # 查询
       POST     /shop/_doc/_search 
       {
       	"query": {
       		"match": {
       			"desc": "慕课网"
       		}
       	}
       }
       # 判断某个字段是否存在 
       {
       	"query": {
       		"exists": {
       			"field": "desc"
       		}
       	}
       }
       ```

       * 语法格式为一个json object，内容都是key-value键值对，json可以嵌套。

       * key可以是一些es的关键字，也可以是某个field字段

       搜索不合法问题定位

       DSL查询的时候经常会出现一些错误查询，出现这样的问题大多都是json无法被es解析，他会像java那样报一个异常信息，根据异常信息去推断问题所在，比如j 对，关键词不存在未注册等等，甚至有时候不能定位问题直接复制错误信息到百度一搜就能定位问题了。

    3. match_all

       在索引中查询所有的文档

       > GET     /shop/_doc/_search 

       或者

       > POST     /shop/_doc/_search 

       ```json
       {
       	"query": {
       		"match_all": {}
       	},
       	"_source": [
       		"id",
       		"nickname",
       		"age"
       	]
       }
       ```

    4. 分页查询

       默认查询是只有10条记录，可以通过分页来展示

       > POST     /shop/_doc/_search 

       ```json
       {
       	"query": {
       		"match_all": {}
       	},
       	"from": 0,
       	"size": 10
       }
       {
       	"query": {
       		"match_all": {}
       	},
       	"_source": [
       		"id",
       		"nickname",
       		"age"
       	],
       	"from": 5,
       	"size": 5
       }
       ```

    5. term/match

       term精确搜索与match分词搜索

       搜索的时候会把用户搜索内容，比如“慕课网强大”作为一整个关键词去搜索，而不会对其进行分词后再搜索

       > POST     /shop/_doc/_search 

       ```json
       {
       	"query": {
       		"term": {
       			"desc": "慕课网"
       		}
       	}
       }
       对比 
       {
       	"query": {
       		"match": {
       			"desc": "慕课网"
       		}
       	}
       }
       注：match会对 慕课网 先进行分词（其实就是全文检索），在查询，而term则不会，直接把 慕课网 作为一个整的词汇去搜索。 
       ```

       terms 多个词语匹配检索

       相当于是tag标签查询，比如慕课网的一些课程会打上 前端 / 后端 / 大数据 / 就业课 这样的标签，可以完全匹配做类似标签的查询

       > POST     /shop/_doc/_search 

       ```json
       {
       	"query": {
       		"terms": {
       			"desc": [
       				"慕课网",
       				"学习",
       				"骚年"
       			]
       		}
       	}
       }
       ```

    6. match_phrase

       match_phrase 短语匹配

       match：分词后只要有匹配就返回，match_phrase：分词结果必须在text字段分词中都包含，而且顺序必须相同，而且必须都是连续的。（搜索比较严格）

       * slop：允许词语间跳过的数量

         > POST     /shop/_doc/_search 

         ```json
         {
         	"query": {
         		"match_phrase": {
         			"desc": {
         				"query": "大学 毕业 研究生",
         				"slop": 2
         			}
         		}
         	}
         }
         ```

    7.  match（operator）/ids

       * operator

         * or：搜索内容分词后，只要存在一个词语匹配就展示结果 
         * and：搜索内容分词后，都要满足词语匹配

         > POST     /shop/_doc/_search 

         ```json
         {
         	"query": {
         		"match": {
         			"desc": "慕课网"
         		}
         	}
         }
         # 等同于 
         {
         	"query": {
         		"match": {
         			"desc": {
         				"query": "xbox游戏机",
         				"operator": "or"
         			}
         		}
         	}
         }
         # 相当于 select * from shop where desc='xbox' or|and desc='游戏机' 
         ```

       * minimum_should_match: 最低匹配精度，至少有[分词后的词语个数]x百分百，得出一个数据值取整。举个例子：当前属性设置为 70 ，若一个用户查询检 有10个词语，那么匹配度按照 10x70%=7，则desc中至少需要有7个词语匹配，就展示；若分词后有8个，则 8x70%=5.6，则desc中至少需要有5个词语匹 示。

       * minimum_should_match 也能设置具体的数字，表示个数

         > POST     /shop/_doc/_search 

         ```json
         {
         	"query": {
         		"match": {
         			"desc": {
         				"query": "女友生日送我好玩的xbox游戏机",
         				"minimum_should_match": "60%"
         			}
         		}
         	}
         }
         ```

    8.  multi_match/boost

       multi_match

       满足使用match在多个字段中进行查询的需求

       > POST     /shop/_doc/_search 

       ```json
       {
       	"query": {
       		"multi_match": {
       			"query": "皮特帕克慕课网",
       			"fields": [
       				"desc",
       				"nickname"
       			]
       		}
       	}
       }
       ```

       boost

       权重，为某个字段设置权重，权重越高，文档相关性得分就越高。通畅来说搜索商品名称要比商品简介的权重更高。

       > POST     /shop/_doc/_search

       ```json
       {
       	"query": {
       		"multi_match": {
       			"query": "皮特帕克慕课网",
       			"fields": [
       				"desc",
       				"nickname^10"
       			]
       		}
       	}
       }
       ```

       nickname^10 代表搜索提升10倍相关性，也就是说用户搜索的时候其实以这个nickname为主，desc为辅，nickname的匹配相关度当然要提高权重比例了。

    9. 布尔查询

       可以组合多重查询

       * must：查询必须匹配搜索条件，譬如 and 
       * should：查询匹配满足1个以上条件，譬如 or 
       * must_not：不匹配搜索条件，一个都不要满足

       > POST     /shop/_doc/_search 

       ```json
       {
       	"query": {
       		"bool": {
       			"must": [
       				{
       					"multi_match": {
       						"query": "慕课网",
       						"fields": [
       							"desc",
       							"nickname"
       						]
       					}
       				},
       				{
       					"term": {
       						"sex": 1
       					}
       				},
       				{
       					"term": {
       						"birthday": "1996-01-14"
       					}
       				}
       			]
       		}
       	}
       }
       {
       	"query": {
       		"bool": {
       			"should（must_not）": [
       				{
       					"multi_match": {
       						"query": "学习",
       						"fields": [
       							"desc",
       							"nickname"
       						]
       					}
       				},
       				{
       					"match": {
       						"desc": "游戏"
       					}
       				},
       				{
       					"term": {
       						"sex": 0
       					}
       				}
       			]
       		}
       	}
       }
       ```

    10. 过滤器

        对搜索出来的结果进行数据过滤。不会到es库里去搜，不会去计算文档的相关度分数，所以过滤的性能会比较高，过滤器可以和全文搜索结合在一起使用。 post_filter元素是一个顶层元素，只会对搜索结果进行过滤。不会计算数据的匹配度相关性分数，不会根据分数去排序，query则相反，会计算分数，也会按照分 使用场景：

        * query：根据用户搜索条件检索匹配记录 
        * post_filter：用于查询后，对结果数据的筛选

        实操：查询账户金额大于80元，小于160元的用户。并且生日在1998-07-14的用户

        * gte：大于等于 
        * lte：小于等于 
        * gt：大于 
        * lt：小于 

        （除此以外还能做其他的match等操作也行）

        > POST     /shop/_doc/_search 

        ```json
        {
        	"query": {
        		"match": {
        			"desc": "慕课网游戏"
        		}
        	},
        	"post_filter": {
        		"range": {
        			"money": {
        				"gt": 60,
        				"lt": 1000
        			}
        		}
        	}
        }
        ```

    11.  DSL搜索 - 排序

        es的排序同sql，可以desc也可以asc。也支持组合排序。

        > POST     /shop/_doc/_search 

        ```json
        {
        	"query": {
        		"match": {
        			"desc": "慕课网游戏"
        		}
        	},
        	"post_filter": {
        		"range": {
        			"money": {
        				"gt": 55.8,
        				"lte": 155.8
        			}
        		}
        	},
        	"sort": [
        		{
        			"age": "desc"
        		},
        		{
        			"money": "desc"
        		}
        	]
        }
        ```

        对文本排序

        由于文本会被分词，所以往往要去做排序会报错，通常我们可以为这个字段增加额外的一个附属属性，类型为keyword，用于做排序。

        * 创建新的索引

          > POST        /shop2/_mapping 

          ```json
          {
          	"properties": {
          		"id": {
          			"type": "long"
          		},
          		"nickname": {
          			"type": "text",
          			"analyzer": "ik_max_word",
          			"fields": {
          				"keyword": {
          					"type": "keyword"
          				}
          			}
          		}
          	}
          }
          ```

    12. DSL搜索 - 高亮highlight

        高亮显示

        > POST     /shop/_doc/_search 

        ```json
        {
        	"query": {
        		"match": {
        			"desc": "慕课网"
        		}
        	},
        	"highlight": {
        		"pre_tags": [
        			"<tag>"
        		],
        		"post_tags": [
        			"</tag>"
        		],
        		"fields": {
        			"desc": {}
        		}
        	}
        }
        ```

    13. 拓展 - prefix-fuzzy-wildcard

        prefix

        根据前缀去查询

        > POST     /shop/_doc/_search 

        ```json
        {
        	"query": {
        		"prefix": {
        			"desc": "imo"
        		}
        	}
        }
        ```

        fuzzy

        模糊搜索，并不是指的sql的模糊搜索，而是用户在进行搜索的时候的打字错误现象，搜索引擎会自动纠正，然后尝试匹配索引库中的数据。

        > POST     /shop/_doc/_search 

        ```json
        {
        	"query": {
        		"fuzzy": {
        			"desc": "imoov.coom"
        		}
        	}
        }
        # 或多字段搜索 
        {
        	"query": {
        		"multi_match": {
        			"fields": [
        				"desc",
        				"nickname"
        			],
        			"query": "imcoc supor",
        			"fuzziness": "AUTO"
        		}
        	}
        }
        {
        	"query": {
        		"multi_match": {
        			"fields": [
        				"desc",
        				"nickname"
        			],
        			"query": "演说",
        			"fuzziness": "1"
        		}
        	}
        }
        ```

        wildcard

        占位符查询。

        * ？：1个字符
        * *：1个或多个字符

    14. 深度分页

        分页查询

        > POST     /shop/_doc/_search 

        ```json
        {
        	"query": {
        		"match_all": {}
        	},
        	"from": 0,
        	"size": 10
        }
        ```

        深度分页

        深度分页其实就是搜索的深浅度，比如第1页，第2页，第10页，第20页，是比较浅的；第10000页，第20000页就是很深了。
        使用如下操作：

        ```json
        {
        	"query": {
        		"match_all": {}
        	},
        	"from": 9990,
        	"size": 10
        }
        {
        	"query": {
        		"match_all": {}
        	},
        	"from": 9999,
        	"size": 10
        }
        ```

        我们在获取第9999条到10009条数据的时候，其实每个分片都会拿到10009条数据，然后集合在一起，总共是10009*3=30027条数据，针对30027数据再次做排序 会获取最后10条数据。

        如此一来，搜索得太深，就会造成性能问题，会耗费内存和占用cpu。而且es为了性能，他不支持超过一万条数据以上的分页查询。那么如何解决深度分页带来的 实我们应该避免深度分页操作（限制分页页数），比如最多只能提供100页的展示，从第101页开始就没了，毕竟用户也不会搜的那么深，我们平时搜索淘宝或者 也就看个10来页就顶多了。

    15. 深度分页 - 提升搜索量

        提升搜索量

        “changing the [index.max_result_window] index level setting”

        通过设置index.max_result_window来突破10000数据

        > GET     /shop/_settings 
        >
        > PUT     /shop/_settings 

        ```json
        {
        	"index.max_result_window": "20000"
        }
        ```

    16. scroll 滚动搜索

        一次性查询1万+数据，往往会造成性能影响，因为数据量太多了。这个时候可以使用滚动搜索，也就是 scroll 。 滚动搜索可以先查询出一些数据，然后再紧接着依次往下查询。在第一次查询的时候会有一个滚动id，相当于一个 锚标记 ，随后再次滚动搜索会需要上一次搜索 ，根据这个进行下一次的搜索请求。每次搜索都是基于一个历史的数据快照，查询数据的期间，如果有数据变更，那么和搜索是没有关系的，搜索的内容还是快照。

        * scroll=1m，相当于是一个session会话时间，搜索保持的上下文时间为1分钟。

        > POST    /shop/_search?scroll=1m 

        ```json
        {
        	"query": {
        		"match_all": {}
        	},
        	"sort": [
        		"_doc"
        	],
        	"size": 5
        }
        ```

        > POST    /_search/scroll 

        ```json
        {
        	"scroll": "1m",
        	"scroll_id": "your last scroll_id"
        }
        ```

        

15. **批量操作 bulk**

**基本语法**

bulk操作和以往的普通请求格式有区别。不要格式化json，不然就不在同一行了，这个需要注意。

```
{ action: { metadata }}\n 
{ request body        }\n 
{ action: { metadata }}\n 
{ request body        }\n 
...
```

* { action: { metadata }} 代表批量操作的类型，可以是新增、删除或修改 
* \n 是每行结尾必须填写的一个规范，每一行包括后一行都要写，用于es的解析 
* { request body } 是请求body，增加和修改操作需要，删除操作则不需要

**批量操作的类型**

action 必须是以下选项之一:

* create：如果文档不存在，那么就创建它。存在会报错。发生异常报错不会影响其他操作。 
* index：创建一个新文档或者替换一个现有的文档。 
* update：部分更新一个文档。 
* delete：删除一个文档。

metadata 中需要指定要操作的文档的 _index 、 _type 和 _id ， _index 、 _type 也可以在url中指定

**实操**

* create新增文档数据，在metadata中指定index以及type

  ```j
  POST    /_bulk 
  {"create": {"_index": "shop2", "_type": "_doc", "_id": "2001"}} 
  {"id": "2001", "nickname": "name2001"} 
  {"create": {"_index": "shop2", "_type": "_doc", "_id": "2002"}} 
  {"id": "2002", "nickname": "name2002"} 
  {"create": {"_index": "shop2", "_type": "_doc", "_id": "2003"}} 
  {"id": "2003", "nickname": "name2003"} 
  ```

* create创建已有id文档，在url中指定index和type

  ```
  POST    /shop/_doc/_bulk 
  {"create": {"_id": "2003"}} 
  {"id": "2003", "nickname": "name2003"} 
  {"create": {"_id": "2004"}} 
  {"id": "2004", "nickname": "name2004"} 
  {"create": {"_id": "2005"}} 
  {"id": "2005", "nickname": "name2005"} 
  ```

* index创建，已有文档id会被覆盖，不存在的id则新增

  ```
  POST    /shop/_doc/_bulk
  {"index": {"_id": "2004"}} 
  {"id": "2004", "nickname": "index2004"} 
  {"index": {"_id": "2007"}} 
  {"id": "2007", "nickname": "name2007"} 
  {"index": {"_id": "2008"}} 
  {"id": "2008", "nickname": "name2008"} 
  ```

  